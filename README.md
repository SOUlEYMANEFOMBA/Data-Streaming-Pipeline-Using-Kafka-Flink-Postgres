# Data-Streaming-Pipeline-Using-Kafka-Flink-Postgres

In this project we mainly use: Kafka to ingest data, Spark to process data flows, and Cassandra to store results and the Airflow DAG to orchestrate these steps